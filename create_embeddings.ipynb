# ============================================
# OPTIMIZED EMBEDDING CREATION
# Model: Alibaba-NLP/gte-base-en-v1.5
# ============================================

import os
os.environ['TOKENIZERS_PARALLELISM'] = 'true'  # Enable parallelism
os.environ['OMP_NUM_THREADS'] = str(os.cpu_count())

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import multiprocessing as mp

print(f"Using {os.cpu_count()} CPU cores")

# ============================================
# FUNCTION DEFINITION
# ============================================

def create_and_save_embeddings(text_file: str, output_prefix: str, embedder=None):
    """Create embeddings from a text file and save them"""
    
    # Skip if already exists
    if os.path.exists(f"{output_prefix}_embeddings.npy"):
        print(f"  ✓ Embeddings already exist for {text_file}, skipping...")
        return
    
    print(f"\nProcessing {text_file}...")
    
    # Load model if not provided
    if embedder is None:
        embedder = SentenceTransformer(
            'Alibaba-NLP/gte-base-en-v1.5',
            trust_remote_code=True,
            device='cpu'
        )
        embedder.max_seq_length = 8192
    
    # Read and parse file
    with open(text_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    individual_analyses = content.split('</analysis>')
    texts = [a.strip() for a in individual_analyses 
             if a.strip() and '<analysis>' in a]
    
    if not texts:
        print(f"  ⚠ No analyses found in {text_file}")
        return
    
    print(f"  Creating embeddings for {len(texts)} analyses...")
    
    # Optimized encoding
    embeddings = embedder.encode(
        texts,
        batch_size=64,  # Much larger batch
        normalize_embeddings=True,
        show_progress_bar=True,
        convert_to_numpy=True
    )
    
    embeddings = np.array(embeddings, dtype='float32')
    
    # Create optimized FAISS index
    dimension = embeddings.shape[1]
    
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings)
    
    # Save
    np.save(f"{output_prefix}_embeddings.npy", embeddings)
    faiss.write_index(index, f"{output_prefix}_index.faiss")
    
    print(f"  ✓ Saved embeddings and index")

# ============================================
# CREATE EMBEDDINGS
# ============================================

print("="*80)
print("CREATING EMBEDDINGS")
print("="*80)

# Load model once
print("\nLoading model...")
embedder = SentenceTransformer(
    'Alibaba-NLP/gte-base-en-v1.5',
    trust_remote_code=True,
    device='cpu'
)
embedder.max_seq_length = 8192  # Full capacity for 1,500-word analyses
print("✓ Model loaded!")

# Process sequentially
create_and_save_embeddings('equity_analyses.txt', 
                           'morningstar_embeddings_equity', embedder)
create_and_save_embeddings('fixed_income_analyses.txt', 
                           'morningstar_embeddings_fixed_income', embedder)
create_and_save_embeddings('allocation_analyses.txt', 
                           'morningstar_embeddings_allocation', embedder)

print("\n" + "="*80)
print("✓ COMPLETE!")
print("="*80)
print("\nFiles created:")
print("  • morningstar_embeddings_equity_embeddings.npy + index.faiss")
print("  • morningstar_embeddings_fixed_income_embeddings.npy + index.faiss")
print("  • morningstar_embeddings_allocation_embeddings.npy + index.faiss")
